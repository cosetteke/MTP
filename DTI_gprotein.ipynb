{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38064bitda74fdf623974235942dd8c620d67e3f",
   "display_name": "Python 3.8.0 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, confusion_matrix\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_to_calculate = ['auroc', 'aupr']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[1.        , 0.2826283 , 0.08349522, ..., 0.01975119, 0.06815311,\n",
       "        0.19913334],\n",
       "       [0.2826283 , 1.        , 0.06314988, ..., 0.02294885, 0.05182183,\n",
       "        0.2035093 ],\n",
       "       [0.08349522, 0.06314988, 1.        , ..., 0.01932024, 0.05582016,\n",
       "        0.04895691],\n",
       "       ...,\n",
       "       [0.01975119, 0.02294885, 0.01932024, ..., 1.        , 0.02354822,\n",
       "        0.0296562 ],\n",
       "       [0.06815311, 0.05182183, 0.05582016, ..., 0.02354822, 1.        ,\n",
       "        0.05182548],\n",
       "       [0.19913334, 0.2035093 , 0.04895691, ..., 0.0296562 , 0.05182548,\n",
       "        1.        ]])"
      ]
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "drug_features = np.loadtxt('/Users/mac/OneDrive/thesis/scripts/dataset/DPI_Gprotein/dpig_X1.txt')\n",
    "drug_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "interaction_matrix = np.loadtxt('/Users/mac/OneDrive/thesis/scripts/dataset/DPI_Gprotein/dpig_Y.txt')\n",
    "interaction_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "metric_values_per_fold = {}\n",
    "if 'auroc' in metrics_to_calculate:\n",
    "    metric_values_per_fold['auroc_micro'] = []\n",
    "    metric_values_per_fold['auroc_macro'] = []\n",
    "if 'aupr' in metrics_to_calculate:\n",
    "    metric_values_per_fold['aupr_micro'] = []\n",
    "    metric_values_per_fold['aupr_macro'] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======================= Fold 0 =======================\n",
      "(10, 223)\n",
      "60 out of the 223 total labels has more than one classes present\n",
      "========================================================================\n",
      "\n",
      "======================= Fold 1 =======================\n",
      "(10, 223)\n",
      "67 out of the 223 total labels has more than one classes present\n",
      "========================================================================\n",
      "\n",
      "======================= Fold 2 =======================\n",
      "(10, 223)\n",
      "62 out of the 223 total labels has more than one classes present\n",
      "========================================================================\n",
      "\n",
      "======================= Fold 3 =======================\n",
      "(10, 223)\n",
      "42 out of the 223 total labels has more than one classes present\n",
      "========================================================================\n",
      "\n",
      "======================= Fold 4 =======================\n",
      "(10, 223)\n",
      "86 out of the 223 total labels has more than one classes present\n",
      "========================================================================\n",
      "\n",
      "======================= Fold 5 =======================\n",
      "(9, 223)\n",
      "22 out of the 223 total labels has more than one classes present\n",
      "========================================================================\n",
      "\n",
      "======================= Fold 6 =======================\n",
      "(9, 223)\n",
      "24 out of the 223 total labels has more than one classes present\n",
      "========================================================================\n",
      "\n",
      "======================= Fold 7 =======================\n",
      "(9, 223)\n",
      "42 out of the 223 total labels has more than one classes present\n",
      "========================================================================\n",
      "\n",
      "======================= Fold 8 =======================\n",
      "(9, 223)\n",
      "56 out of the 223 total labels has more than one classes present\n",
      "========================================================================\n",
      "\n",
      "======================= Fold 9 =======================\n",
      "(9, 223)\n",
      "43 out of the 223 total labels has more than one classes present\n",
      "========================================================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "fold_counter = 0\n",
    "for train_index, test_index in kf.split(drug_features):\n",
    "    print('======================= Fold '+str(fold_counter)+' =======================')\n",
    "    \n",
    "    # split the dataset\n",
    "    X_train, X_test = drug_features[train_index], drug_features[test_index]\n",
    "    y_train, y_test = interaction_matrix[train_index], interaction_matrix[test_index]\n",
    "    \n",
    "    # define the oneVSrest classifier with the base classifier\n",
    "    clf = OneVsRestClassifier(RandomForestClassifier())\n",
    "    \n",
    "    #clf = OneVsRestClassifier(LogisticRegression(random_state=0))\n",
    "    \n",
    "    # fit the classifier on the training set\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # generate probability predictions for every sample in the test set\n",
    "    y_pred = clf.predict_proba(X_test)\n",
    "    \n",
    "    print(str(y_pred.shape))\n",
    "    \n",
    "    # calculate the performance metrics on the test set\n",
    "    if 'auroc' in metrics_to_calculate:\n",
    "        metric_values_per_fold['auroc_micro'].append(roc_auc_score(y_test, y_pred, average='micro'))\n",
    "        \n",
    "        # This is not really important as we are only interested in the micro measures.\n",
    "        # Nevertheless, I basically do the macro averaging by hand so that I can skip labels that have only samples with one class\n",
    "        roc_auc_per_label = []\n",
    "        for label_idx in range(interaction_matrix.shape[1]):\n",
    "            if len(set(y_test[:, label_idx])) >= 2:\n",
    "                roc_auc_per_label.append(roc_auc_score(y_test[:, label_idx], y_pred[:, label_idx]))\n",
    "        print(str(len(roc_auc_per_label))+' out of the '+str(y_test.shape[1])+' total labels has more than one classes present')\n",
    "        \n",
    "        metric_values_per_fold['auroc_macro'].append(np.mean(roc_auc_per_label))\n",
    "\n",
    "        \n",
    "    if 'aupr' in metrics_to_calculate:\n",
    "        metric_values_per_fold['aupr_micro'].append(average_precision_score(y_test, y_pred, average='micro'))\n",
    "        \n",
    "        aupr_per_label = []\n",
    "        for label_idx in range(interaction_matrix.shape[1]):\n",
    "            if len(set(y_test[:, label_idx])) >= 2:\n",
    "                aupr_per_label.append(average_precision_score(y_test[:, label_idx], y_pred[:, label_idx]))\n",
    "        \n",
    "        metric_values_per_fold['aupr_macro'].append(np.mean(aupr_per_label))\n",
    "\n",
    "    \n",
    "    fold_counter += 1\n",
    "    print('========================================================================')\n",
    "    print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'auroc_micro': [0.8005691432087372,\n",
       "  0.9333683769080078,\n",
       "  0.7761687776748019,\n",
       "  0.909435261707989,\n",
       "  0.8523912829444338,\n",
       "  0.9603714910068919,\n",
       "  0.8063340389374198,\n",
       "  0.6383792048929664,\n",
       "  0.821747465728242,\n",
       "  0.906439586903163],\n",
       " 'auroc_macro': [0.8135416666666667,\n",
       "  0.9229003790570955,\n",
       "  0.8155801971326164,\n",
       "  0.9246031746031745,\n",
       "  0.8266493632336654,\n",
       "  0.9545454545454546,\n",
       "  0.78125,\n",
       "  0.684311224489796,\n",
       "  0.8246173469387755,\n",
       "  0.9127906976744186],\n",
       " 'aupr_micro': [0.2791824455888884,\n",
       "  0.7181381742244055,\n",
       "  0.5318738886999742,\n",
       "  0.5905404975998026,\n",
       "  0.5734453546691645,\n",
       "  0.702899977851615,\n",
       "  0.5179722016336363,\n",
       "  0.3015611069293883,\n",
       "  0.2596979142727353,\n",
       "  0.4133263365340298],\n",
       " 'aupr_macro': [0.6188888888888889,\n",
       "  0.8445273631840796,\n",
       "  0.6786482334869431,\n",
       "  0.8317460317460317,\n",
       "  0.6852390180878554,\n",
       "  0.8686868686868686,\n",
       "  0.638888888888889,\n",
       "  0.4457671957671958,\n",
       "  0.6259424603174603,\n",
       "  0.7642118863049097]}"
      ]
     },
     "metadata": {},
     "execution_count": 11
    }
   ],
   "source": [
    "metric_values_per_fold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "auroc_micro: 0.8405204629912653 (0.0896325685104234)\n\nauroc_macro: 0.8460789504341664 (0.07841018648994735)\n\naupr_micro: 0.48886378980036393 (0.15994969893477)\n\naupr_macro: 0.7002546835359122 (0.1232595455378644)\n\n"
     ]
    }
   ],
   "source": [
    "# calculate the mean and std for every metric measured during training and validation\n",
    "for metric_name in metric_values_per_fold.keys():\n",
    "    print(metric_name+': '+ str(np.mean(metric_values_per_fold[metric_name])) +' ('+ str(np.std(metric_values_per_fold[metric_name])) +')')\n",
    "    print('')"
   ]
  }
 ]
}