{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python38064bitda74fdf623974235942dd8c620d67e3f",
   "display_name": "Python 3.8.0 64-bit"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, confusion_matrix\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_to_calculate = ['auroc', 'aupr']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "======================= Fold 0 =======================\n",
      "(3, 54)\n",
      "11 out of the 54 total labels has more than one classes present\n",
      "========================================================================\n",
      "\n",
      "======================= Fold 1 =======================\n",
      "(3, 54)\n",
      "6 out of the 54 total labels has more than one classes present\n",
      "========================================================================\n",
      "\n",
      "======================= Fold 2 =======================\n",
      "(3, 54)\n",
      "23 out of the 54 total labels has more than one classes present\n",
      "========================================================================\n",
      "\n",
      "======================= Fold 3 =======================\n",
      "(3, 54)\n",
      "7 out of the 54 total labels has more than one classes present\n",
      "========================================================================\n",
      "\n",
      "======================= Fold 4 =======================\n",
      "(3, 54)\n",
      "4 out of the 54 total labels has more than one classes present\n",
      "========================================================================\n",
      "\n",
      "======================= Fold 5 =======================\n",
      "(3, 54)\n",
      "8 out of the 54 total labels has more than one classes present\n",
      "========================================================================\n",
      "\n",
      "======================= Fold 6 =======================\n",
      "(2, 54)\n",
      "2 out of the 54 total labels has more than one classes present\n",
      "========================================================================\n",
      "\n",
      "======================= Fold 7 =======================\n",
      "(2, 54)\n",
      "4 out of the 54 total labels has more than one classes present\n",
      "========================================================================\n",
      "\n",
      "======================= Fold 8 =======================\n",
      "(2, 54)\n",
      "13 out of the 54 total labels has more than one classes present\n",
      "========================================================================\n",
      "\n",
      "======================= Fold 9 =======================\n",
      "(2, 54)\n",
      "8 out of the 54 total labels has more than one classes present\n",
      "========================================================================\n",
      "\n",
      "auroc_micro: 0.6168185149376336 (0.19826510180042523)\n",
      "\n",
      "auroc_macro: 0.7332977710695101 (0.14468349139490863)\n",
      "\n",
      "aupr_micro: 0.4436393199281456 (0.23442266149430796)\n",
      "\n",
      "aupr_macro: 0.687250732359428 (0.1867862464858829)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "drug_features = np.loadtxt('/Users/mac/OneDrive/thesis/scripts/dataset/DPI_nuclear/dpin_X1.txt')\n",
    "interaction_matrix = np.loadtxt('/Users/mac/OneDrive/thesis/scripts/dataset/DPI_nuclear/dpin_Y.txt')\n",
    "metric_values_per_fold = {}\n",
    "if 'auroc' in metrics_to_calculate:\n",
    "    metric_values_per_fold['auroc_micro'] = []\n",
    "    metric_values_per_fold['auroc_macro'] = []\n",
    "if 'aupr' in metrics_to_calculate:\n",
    "    metric_values_per_fold['aupr_micro'] = []\n",
    "    metric_values_per_fold['aupr_macro'] = []\n",
    "kf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
    "fold_counter = 0\n",
    "for train_index, test_index in kf.split(drug_features):\n",
    "    print('======================= Fold '+str(fold_counter)+' =======================')\n",
    "    \n",
    "    # split the dataset\n",
    "    X_train, X_test = drug_features[train_index], drug_features[test_index]\n",
    "    y_train, y_test = interaction_matrix[train_index], interaction_matrix[test_index]\n",
    "    \n",
    "    # define the oneVSrest classifier with the base classifier\n",
    "    clf = OneVsRestClassifier(RandomForestClassifier())\n",
    "    \n",
    "    #clf = OneVsRestClassifier(LogisticRegression(random_state=0))\n",
    "    \n",
    "    # fit the classifier on the training set\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    # generate probability predictions for every sample in the test set\n",
    "    y_pred = clf.predict_proba(X_test)\n",
    "    \n",
    "    print(str(y_pred.shape))\n",
    "    \n",
    "    # calculate the performance metrics on the test set\n",
    "    if 'auroc' in metrics_to_calculate:\n",
    "        metric_values_per_fold['auroc_micro'].append(roc_auc_score(y_test, y_pred, average='micro'))\n",
    "        \n",
    "        # This is not really important as we are only interested in the micro measures.\n",
    "        # Nevertheless, I basically do the macro averaging by hand so that I can skip labels that have only samples with one class\n",
    "        roc_auc_per_label = []\n",
    "        for label_idx in range(interaction_matrix.shape[1]):\n",
    "            if len(set(y_test[:, label_idx])) >= 2:\n",
    "                roc_auc_per_label.append(roc_auc_score(y_test[:, label_idx], y_pred[:, label_idx]))\n",
    "        print(str(len(roc_auc_per_label))+' out of the '+str(y_test.shape[1])+' total labels has more than one classes present')\n",
    "        \n",
    "        metric_values_per_fold['auroc_macro'].append(np.mean(roc_auc_per_label))\n",
    "\n",
    "        \n",
    "    if 'aupr' in metrics_to_calculate:\n",
    "        metric_values_per_fold['aupr_micro'].append(average_precision_score(y_test, y_pred, average='micro'))\n",
    "        \n",
    "        aupr_per_label = []\n",
    "        for label_idx in range(interaction_matrix.shape[1]):\n",
    "            if len(set(y_test[:, label_idx])) >= 2:\n",
    "                aupr_per_label.append(average_precision_score(y_test[:, label_idx], y_pred[:, label_idx]))\n",
    "        \n",
    "        metric_values_per_fold['aupr_macro'].append(np.mean(aupr_per_label))\n",
    "\n",
    "    \n",
    "    fold_counter += 1\n",
    "    print('========================================================================')\n",
    "    print('')\n",
    "    # calculate the mean and std for every metric measured during training and validation\n",
    "for metric_name in metric_values_per_fold.keys():\n",
    "    print(metric_name+': '+ str(np.mean(metric_values_per_fold[metric_name])) +' ('+ str(np.std(metric_values_per_fold[metric_name])) +')')\n",
    "    print('')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}