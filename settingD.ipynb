{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load packages\n",
    "import numpy as np\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, confusion_matrix\n",
    "import sklearn.metrics as metrics\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.preprocessing import StandardScaler, MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load \n",
    "import numpy as np\n",
    "from Extrabictree import build_bd as ebuild_bd\n",
    "from Extrabictree import bdtrain as ebdtrain\n",
    "from Extrabictree import bdtest as ebdtest\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import  average_precision_score\n",
    "from sklearn.model_selection import KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split rows and columns\n",
    "X1kf = KFold(n_splits=5, shuffle=False)\n",
    "X2kf = KFold(n_splits=5, shuffle=False) #返回的是fold数目\n",
    "X1_splits = list(X1kf.split(X1))\n",
    "X2_splits = list(X2kf.split(X2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "msleaf = 2\n",
    "cs = 2\n",
    "nof_trees = 10\n",
    "epochs = 10 #100\n",
    "\n",
    "# Load datasets\n",
    "dataname = 'dpie'\n",
    "\n",
    "# define method\n",
    "## 'random_forest', 'logistic_regression', 'mlp_per_target', 'mlp'\n",
    "method_name = 'mlp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "auc: 0.5016218199841774\n",
      "aupr: 0.014869848826943062\n",
      "auc: 0.5246027661014363\n",
      "aupr: 0.01537733444746987\n",
      "auc: 0.5167324354465128\n",
      "aupr: 0.01505104864149548\n",
      "auc: 0.5149859883903806\n",
      "aupr: 0.014902115344379945\n",
      "auc: 0.5256343351157625\n",
      "aupr: 0.0153225315562253\n",
      "auc: 0.5254484668248931\n",
      "aupr: 0.01533133570118223\n",
      "auc: 0.5291084041062595\n",
      "aupr: 0.01555876940138053\n",
      "auc: 0.5269744931514684\n",
      "aupr: 0.015493148366567669\n",
      "auc: 0.5293640921525454\n",
      "aupr: 0.015417660296370126\n",
      "auc: 0.5241216531793008\n",
      "aupr: 0.015326177072363993\n",
      "===========================================\n",
      "auc: 0.4604881014229226\n",
      "aupr: 0.024531801478015782\n",
      "auc: 0.4168849395330043\n",
      "aupr: 0.02296640323882951\n",
      "auc: 0.380360312581176\n",
      "aupr: 0.022042483464499066\n",
      "auc: 0.3723326213909814\n",
      "aupr: 0.02166037048140021\n",
      "auc: 0.3602232877305394\n",
      "aupr: 0.02125866749898404\n",
      "auc: 0.3514762882308232\n",
      "aupr: 0.021084185103490406\n",
      "auc: 0.3486140875592884\n",
      "aupr: 0.02077665970865196\n",
      "auc: 0.3436677718609596\n",
      "aupr: 0.020680034115189583\n",
      "auc: 0.3407018464802148\n",
      "aupr: 0.020623620003036514\n",
      "auc: 0.3863106533995247\n",
      "aupr: 0.019511456641676625\n",
      "===========================================\n",
      "auc: 0.3986531267394146\n",
      "aupr: 0.011037964693169127\n",
      "auc: 0.36190050871810797\n",
      "aupr: 0.010574415657927085\n",
      "auc: 0.34006219823178385\n",
      "aupr: 0.010553381532968007\n",
      "auc: 0.3311156201053681\n",
      "aupr: 0.010515023179690233\n",
      "auc: 0.31997624687714393\n",
      "aupr: 0.010614678004455971\n",
      "auc: 0.30996013099814895\n",
      "aupr: 0.010611160726506533\n",
      "auc: 0.30696801418715136\n",
      "aupr: 0.01062957305661215\n",
      "auc: 0.32796299172847654\n",
      "aupr: 0.009974639475942019\n",
      "auc: 0.32595141936235483\n",
      "aupr: 0.009906075498461562\n",
      "auc: 0.32021118920948055\n",
      "aupr: 0.009853471929781032\n",
      "===========================================\n",
      "auc: 0.4238095713425367\n",
      "aupr: 0.004055035006202429\n",
      "auc: 0.4260555062004439\n",
      "aupr: 0.003982751206212202\n",
      "auc: 0.40561500351031293\n",
      "aupr: 0.003926261698170017\n",
      "auc: 0.39361838405818805\n",
      "aupr: 0.003914526557820465\n",
      "auc: 0.40975085095976277\n",
      "aupr: 0.003832876052347435\n",
      "auc: 0.3950366503295701\n",
      "aupr: 0.0037823532043611816\n",
      "auc: 0.392841456962897\n",
      "aupr: 0.0038087564190481538\n",
      "auc: 0.38500647161970164\n",
      "aupr: 0.0037775890510577223\n",
      "auc: 0.36957523549042903\n",
      "aupr: 0.00371810800873251\n",
      "auc: 0.36291229541197106\n",
      "aupr: 0.0036818238292897426\n",
      "===========================================\n",
      "auc: 0.4197907577872786\n",
      "aupr: 0.012950980301485934\n",
      "auc: 0.3618207944332955\n",
      "aupr: 0.012440671752693257\n",
      "auc: 0.35379002704825063\n",
      "aupr: 0.012351534809099087\n",
      "auc: 0.31542022947386783\n",
      "aupr: 0.012315175596336998\n",
      "auc: 0.31225923785010035\n",
      "aupr: 0.012187784739404304\n",
      "auc: 0.30024730608149386\n",
      "aupr: 0.01211276271914423\n",
      "auc: 0.29038123854811965\n",
      "aupr: 0.012128365754921112\n",
      "auc: 0.30233372960474647\n",
      "aupr: 0.011732761506226999\n",
      "auc: 0.30319698324753513\n",
      "aupr: 0.011525739559440775\n",
      "auc: 0.3024798774103481\n",
      "aupr: 0.01152961809520316\n",
      "===========================================\n",
      "auc: 0.5561106784876966\n",
      "aupr: 0.015911905440227376\n",
      "auc: 0.5646245684754952\n",
      "aupr: 0.015237931504378393\n",
      "auc: 0.5982737631713007\n",
      "aupr: 0.015967051903471804\n",
      "auc: 0.6154667266324362\n",
      "aupr: 0.016373508636074792\n",
      "auc: 0.6049036591612289\n",
      "aupr: 0.016179312614737824\n",
      "auc: 0.6067283120329923\n",
      "aupr: 0.016169734308410604\n",
      "auc: 0.6208049988131775\n",
      "aupr: 0.015810915331179815\n",
      "auc: 0.6345245977643318\n",
      "aupr: 0.01611222157698616\n",
      "auc: 0.6380052497810278\n",
      "aupr: 0.015980875115323968\n",
      "auc: 0.6430141960630806\n",
      "aupr: 0.016144566055697984\n",
      "===========================================\n",
      "auc: 0.4565391001289246\n",
      "aupr: 0.007852702705950504\n",
      "auc: 0.45540001071184\n",
      "aupr: 0.008344587034557446\n",
      "auc: 0.49649713266996437\n",
      "aupr: 0.008825079371256575\n",
      "auc: 0.4921798785736419\n",
      "aupr: 0.008723874955422569\n",
      "auc: 0.4723534103820684\n",
      "aupr: 0.008030847400061996\n",
      "auc: 0.47051518212040877\n",
      "aupr: 0.00795925484233007\n",
      "auc: 0.4676430700133516\n",
      "aupr: 0.007773380111046877\n",
      "auc: 0.46992459629752903\n",
      "aupr: 0.007875014056432135\n",
      "auc: 0.4683044304935481\n",
      "aupr: 0.00784358026186422\n",
      "auc: 0.47290717425485757\n",
      "aupr: 0.007833655170319124\n",
      "===========================================\n",
      "auc: 0.39894984763685365\n",
      "aupr: 0.005613928474651003\n",
      "auc: 0.37386880986779003\n",
      "aupr: 0.006067906936016358\n",
      "auc: 0.3694351030120555\n",
      "aupr: 0.005862420970628252\n",
      "auc: 0.34867122339715184\n",
      "aupr: 0.006062558951385998\n",
      "auc: 0.33959984945792715\n",
      "aupr: 0.00605427709807229\n",
      "auc: 0.3568636258786679\n",
      "aupr: 0.006000211749282461\n",
      "auc: 0.3526435916424869\n",
      "aupr: 0.006117826430209732\n",
      "auc: 0.3384288992217946\n",
      "aupr: 0.006011238139967611\n",
      "auc: 0.3123110636283068\n",
      "aupr: 0.006630390115825929\n",
      "auc: 0.33089997450497155\n",
      "aupr: 0.005978407695269229\n",
      "===========================================\n",
      "auc: 0.4229718677180907\n",
      "aupr: 0.005256865963101354\n",
      "auc: 0.39964120924059815\n",
      "aupr: 0.0049331059781152955\n",
      "auc: 0.40651841792564936\n",
      "aupr: 0.004742315861425388\n",
      "auc: 0.41042499344145916\n",
      "aupr: 0.004775068322788528\n",
      "auc: 0.41047283220937947\n",
      "aupr: 0.004595166372330164\n",
      "auc: 0.4064628632274193\n",
      "aupr: 0.004477399745734561\n",
      "auc: 0.40576071356923504\n",
      "aupr: 0.004599432364639422\n",
      "auc: 0.4035917655591735\n",
      "aupr: 0.004623953340982408\n",
      "auc: 0.39865511334701625\n",
      "aupr: 0.004531827498679642\n",
      "auc: 0.4072776654681254\n",
      "aupr: 0.004486761882401106\n",
      "===========================================\n",
      "auc: 0.4031258513585322\n",
      "aupr: 0.015825795883933857\n",
      "auc: 0.33831403362545887\n",
      "aupr: 0.015364416725088809\n",
      "auc: 0.34131531128140524\n",
      "aupr: 0.015276739389357441\n",
      "auc: 0.3187866224657052\n",
      "aupr: 0.015126308797613936\n",
      "auc: 0.3118660610163883\n",
      "aupr: 0.01495683773337163\n",
      "auc: 0.3067053110386417\n",
      "aupr: 0.014773515605440041\n",
      "auc: 0.30262800611045026\n",
      "aupr: 0.014653281732984651\n",
      "auc: 0.2994664595083767\n",
      "aupr: 0.014625201962386659\n",
      "auc: 0.2944459729561326\n",
      "aupr: 0.014393809619227439\n",
      "auc: 0.29707141656169395\n",
      "aupr: 0.014209161718500661\n",
      "===========================================\n",
      "auc: 0.5017825995953393\n",
      "aupr: 0.009437926712155738\n",
      "auc: 0.47760606835817887\n",
      "aupr: 0.009721547074241724\n",
      "auc: 0.4907900958937029\n",
      "aupr: 0.009672279350819034\n",
      "auc: 0.4946366969774491\n",
      "aupr: 0.009555221796547405\n",
      "auc: 0.5032586029132461\n",
      "aupr: 0.009546691866233753\n",
      "auc: 0.5296890625363381\n",
      "aupr: 0.010085761813911314\n",
      "auc: 0.5355934634138778\n",
      "aupr: 0.010217005128626357\n",
      "auc: 0.5349655418343062\n",
      "aupr: 0.010193072758048375\n",
      "auc: 0.5310460708388567\n",
      "aupr: 0.010000422080595449\n",
      "auc: 0.5358675007945921\n",
      "aupr: 0.010005183802115422\n",
      "===========================================\n",
      "auc: 0.48843070656758925\n",
      "aupr: 0.009017624968798602\n",
      "auc: 0.47037801939703167\n",
      "aupr: 0.00897732024782501\n",
      "auc: 0.44850152193133425\n",
      "aupr: 0.00891904689504865\n",
      "auc: 0.4688396370311878\n",
      "aupr: 0.009324058563746788\n",
      "auc: 0.4824783858753974\n",
      "aupr: 0.009679908996346246\n",
      "auc: 0.48809282768767676\n",
      "aupr: 0.009686193092007156\n",
      "auc: 0.4870357434516458\n",
      "aupr: 0.009476377617463776\n",
      "auc: 0.48368479485985405\n",
      "aupr: 0.009359866030767132\n",
      "auc: 0.49736699130035705\n",
      "aupr: 0.00940196351409884\n",
      "auc: 0.5193615987365608\n",
      "aupr: 0.00961881062516189\n",
      "===========================================\n",
      "auc: 0.4934056621998981\n",
      "aupr: 0.008929423594904697\n",
      "auc: 0.45144672368675254\n",
      "aupr: 0.010957812583801772\n",
      "auc: 0.42378159082526906\n",
      "aupr: 0.010753093362536218\n",
      "auc: 0.4275615131983351\n",
      "aupr: 0.010566091038518091\n",
      "auc: 0.4466481673369747\n",
      "aupr: 0.010585082322341979\n",
      "auc: 0.43325708214053643\n",
      "aupr: 0.010457956260626948\n",
      "auc: 0.4304584731027942\n",
      "aupr: 0.010451868766530792\n",
      "auc: 0.4163596129190889\n",
      "aupr: 0.012061014207483135\n",
      "auc: 0.4308848065473576\n",
      "aupr: 0.012004870607961071\n",
      "auc: 0.42464830783821284\n",
      "aupr: 0.01709797598250003\n",
      "===========================================\n",
      "auc: 0.39616722461157594\n",
      "aupr: 0.008252942762973451\n",
      "auc: 0.40834865406477905\n",
      "aupr: 0.008403920780753039\n",
      "auc: 0.37889023847387304\n",
      "aupr: 0.00795672286161009\n",
      "auc: 0.38453932725578804\n",
      "aupr: 0.007829271454310295\n",
      "auc: 0.39626278957009825\n",
      "aupr: 0.007790944516479416\n",
      "auc: 0.39865398203875224\n",
      "aupr: 0.007701867866186577\n",
      "auc: 0.3893837673609674\n",
      "aupr: 0.007526792915537626\n",
      "auc: 0.3795376807253339\n",
      "aupr: 0.00743557970684564\n",
      "auc: 0.3834339178654347\n",
      "aupr: 0.007442784166412264\n",
      "auc: 0.3768093218445775\n",
      "aupr: 0.007378994971742212\n",
      "===========================================\n",
      "auc: 0.42841052588700146\n",
      "aupr: 0.012833829577907133\n",
      "auc: 0.4123845603254133\n",
      "aupr: 0.01236513439673995\n",
      "auc: 0.40464901101586914\n",
      "aupr: 0.012075813952038366\n",
      "auc: 0.37462247516628555\n",
      "aupr: 0.011778367805735311\n",
      "auc: 0.36344832201486243\n",
      "aupr: 0.01161754983053649\n",
      "auc: 0.3563846068795354\n",
      "aupr: 0.011584616536988855\n",
      "auc: 0.3536431510157528\n",
      "aupr: 0.01157031295162561\n",
      "auc: 0.3519733128495196\n",
      "aupr: 0.01158126828668965\n",
      "auc: 0.35047601589823274\n",
      "aupr: 0.011529241713070522\n",
      "auc: 0.3478960446454031\n",
      "aupr: 0.011457232823223931\n",
      "===========================================\n",
      "auc: 0.5764215961974286\n",
      "aupr: 0.022524610844554968\n",
      "auc: 0.570613352106425\n",
      "aupr: 0.018846551822520548\n",
      "auc: 0.5766664626113217\n",
      "aupr: 0.01627632772093069\n",
      "auc: 0.5955543354746391\n",
      "aupr: 0.01585098507314562\n",
      "auc: 0.5865743061161763\n",
      "aupr: 0.01515158406238849\n",
      "auc: 0.5868603024355281\n",
      "aupr: 0.014761278927334795\n",
      "auc: 0.6074207914541623\n",
      "aupr: 0.015162918569397346\n",
      "auc: 0.5936920116158506\n",
      "aupr: 0.014860199862227192\n",
      "auc: 0.5976130626029045\n",
      "aupr: 0.01502096569910913\n",
      "auc: 0.6091849136782123\n",
      "aupr: 0.015519945173710248\n",
      "===========================================\n",
      "auc: 0.5022145700088865\n",
      "aupr: 0.011004624272863594\n",
      "auc: 0.4907607607294392\n",
      "aupr: 0.009479264374275041\n",
      "auc: 0.47787581198292794\n",
      "aupr: 0.009062247921027212\n",
      "auc: 0.4648602262913501\n",
      "aupr: 0.008816340683571375\n",
      "auc: 0.459676990375108\n",
      "aupr: 0.008697634303736124\n",
      "auc: 0.45887439453296114\n",
      "aupr: 0.008639542861123036\n",
      "auc: 0.4450241404558368\n",
      "aupr: 0.008524383601915705\n",
      "auc: 0.4941753132157653\n",
      "aupr: 0.00941489166486334\n",
      "auc: 0.4917690902036372\n",
      "aupr: 0.009387071248345227\n",
      "auc: 0.4874072243012879\n",
      "aupr: 0.00925695922243611\n",
      "===========================================\n",
      "auc: 0.48955768453959503\n",
      "aupr: 0.008290943045194543\n",
      "auc: 0.47054084195366963\n",
      "aupr: 0.007573118958206757\n",
      "auc: 0.46154525018001724\n",
      "aupr: 0.008238757102997875\n",
      "auc: 0.4264186234391191\n",
      "aupr: 0.007910330203580751\n",
      "auc: 0.42360464707845236\n",
      "aupr: 0.007560016435474723\n",
      "auc: 0.4151223238904793\n",
      "aupr: 0.007808455481807079\n",
      "auc: 0.40280914663060463\n",
      "aupr: 0.007660629712935508\n",
      "auc: 0.3983350603277191\n",
      "aupr: 0.007537109095892801\n",
      "auc: 0.393104023604208\n",
      "aupr: 0.0073899535646877\n",
      "auc: 0.3954943009185268\n",
      "aupr: 0.007218884451999293\n",
      "===========================================\n",
      "auc: 0.5340852948376519\n",
      "aupr: 0.01069357164634927\n",
      "auc: 0.5425435635705438\n",
      "aupr: 0.01232881307911423\n",
      "auc: 0.5043800953984704\n",
      "aupr: 0.01132994597984033\n",
      "auc: 0.48397624681943285\n",
      "aupr: 0.010932581896003112\n",
      "auc: 0.4975412268272961\n",
      "aupr: 0.011558149744856893\n",
      "auc: 0.49323457193089165\n",
      "aupr: 0.011503578591818492\n",
      "auc: 0.4943806888570729\n",
      "aupr: 0.011348837465077912\n",
      "auc: 0.4909100687670157\n",
      "aupr: 0.011093768183746449\n",
      "auc: 0.4915094619555945\n",
      "aupr: 0.010823541466906273\n",
      "auc: 0.521992092164121\n",
      "aupr: 0.011533461828007668\n",
      "===========================================\n",
      "auc: 0.5137640634613694\n",
      "aupr: 0.009384205304953768\n",
      "auc: 0.49707697913919896\n",
      "aupr: 0.00935024885359147\n",
      "auc: 0.45864234493568906\n",
      "aupr: 0.008382242859207122\n",
      "auc: 0.4543225916322405\n",
      "aupr: 0.00855283278157476\n",
      "auc: 0.45915736427294834\n",
      "aupr: 0.00818653101771229\n",
      "auc: 0.45867439058334075\n",
      "aupr: 0.008274102054449936\n",
      "auc: 0.4576521344232516\n",
      "aupr: 0.008393551339476255\n",
      "auc: 0.45431572470774373\n",
      "aupr: 0.008889262098476236\n",
      "auc: 0.4499511074975828\n",
      "aupr: 0.009461114129215789\n",
      "auc: 0.4583402002578302\n",
      "aupr: 0.00910788952595454\n",
      "===========================================\n",
      "auc: 0.5219442076753534\n",
      "aupr: 0.007834682494294958\n",
      "auc: 0.5391993786282412\n",
      "aupr: 0.008252347074226436\n",
      "auc: 0.5406534490671858\n",
      "aupr: 0.00833658775739575\n",
      "auc: 0.5438546232177173\n",
      "aupr: 0.008441671580619283\n",
      "auc: 0.5460783473125167\n",
      "aupr: 0.008685007226120624\n",
      "auc: 0.5442813119417363\n",
      "aupr: 0.008675481339887743\n",
      "auc: 0.5518477235702649\n",
      "aupr: 0.00879462316092729\n",
      "auc: 0.5653605418845923\n",
      "aupr: 0.008931564402439848\n",
      "auc: 0.5582984904499396\n",
      "aupr: 0.008798954512281708\n",
      "auc: 0.5571384620040248\n",
      "aupr: 0.008788653121579032\n",
      "===========================================\n",
      "auc: 0.42263798143053644\n",
      "aupr: 0.009831476291783384\n",
      "auc: 0.4108323352938386\n",
      "aupr: 0.010148033882034621\n",
      "auc: 0.4257643895555661\n",
      "aupr: 0.009476621520406932\n",
      "auc: 0.4443056906038041\n",
      "aupr: 0.009718958557105972\n",
      "auc: 0.43961144642603045\n",
      "aupr: 0.009498798047554815\n",
      "auc: 0.4323484857468103\n",
      "aupr: 0.009265989342899012\n",
      "auc: 0.46351177488972156\n",
      "aupr: 0.009579695584089856\n",
      "auc: 0.462630955627757\n",
      "aupr: 0.0093667274800511\n",
      "auc: 0.4525132067305412\n",
      "aupr: 0.009199996660685559\n",
      "auc: 0.45860964699046625\n",
      "aupr: 0.009246231582252632\n",
      "===========================================\n",
      "auc: 0.4239621199516065\n",
      "aupr: 0.056607029828463246\n",
      "auc: 0.4348975445087748\n",
      "aupr: 0.057095058021482584\n",
      "auc: 0.40643145803780667\n",
      "aupr: 0.06843475514022856\n",
      "auc: 0.386341171427524\n",
      "aupr: 0.06334772703841347\n",
      "auc: 0.38383653935638884\n",
      "aupr: 0.06506286407337869\n",
      "auc: 0.3676137148787483\n",
      "aupr: 0.06635606606250379\n",
      "auc: 0.35838129912322014\n",
      "aupr: 0.06642261761024978\n",
      "auc: 0.3619145753018249\n",
      "aupr: 0.06646885566898458\n",
      "auc: 0.39487948154644903\n",
      "aupr: 0.06590255559743001\n",
      "auc: 0.39827809629631716\n",
      "aupr: 0.06530900742668014\n",
      "===========================================\n",
      "auc: 0.45359871390224477\n",
      "aupr: 0.005521576343458347\n",
      "auc: 0.458917878528657\n",
      "aupr: 0.005225034474489138\n",
      "auc: 0.4670208843396951\n",
      "aupr: 0.005399397344484367\n",
      "auc: 0.46485354414324065\n",
      "aupr: 0.005706149851472399\n",
      "auc: 0.476120173446211\n",
      "aupr: 0.005850107275940522\n",
      "auc: 0.4711660422996372\n",
      "aupr: 0.005590913799959305\n",
      "auc: 0.48216719270817965\n",
      "aupr: 0.005668107167093506\n",
      "auc: 0.477439456063243\n",
      "aupr: 0.005515204015262869\n",
      "auc: 0.4733886905990974\n",
      "aupr: 0.0055193432679965645\n",
      "auc: 0.4828707117784136\n",
      "aupr: 0.0055505683726084385\n",
      "===========================================\n",
      "auc: 0.38667789417517406\n",
      "aupr: 0.008085155729229314\n",
      "auc: 0.3880422865765965\n",
      "aupr: 0.008453571800699411\n",
      "auc: 0.38957342415387247\n",
      "aupr: 0.008201185870407794\n",
      "auc: 0.39006990791497664\n",
      "aupr: 0.008457145206811971\n",
      "auc: 0.38524096762225546\n",
      "aupr: 0.008144925404723976\n",
      "auc: 0.39121336295839293\n",
      "aupr: 0.007993356369053857\n",
      "auc: 0.3783889914834902\n",
      "aupr: 0.00772234826482279\n",
      "auc: 0.37164164794257293\n",
      "aupr: 0.007596461240519049\n",
      "auc: 0.37474894429460537\n",
      "aupr: 0.007637421393319292\n",
      "auc: 0.36659218715478536\n",
      "aupr: 0.007553273429469005\n",
      "===========================================\n"
     ]
    }
   ],
   "source": [
    "fold_count = 0\n",
    "auc_dic = {}\n",
    "aupr_dic = {}\n",
    "for i in range(len(X1_splits)):\n",
    "    for j in range(len(X2_splits)):\n",
    "    \n",
    "        X1_train_index, X1_test_index = X1_splits[i]\n",
    "        X2_train_index, X2_test_index = X2_splits[j]\n",
    "\n",
    "        X1_train, X1_test = X1[X1_train_index,:], X1[X1_test_index,:]\n",
    "        X2_train, X2_test = X2[X2_train_index,:], X2[X2_test_index,:]\n",
    "\n",
    "        Y_train = Y[X1_train_index,:][:,X2_train_index]\n",
    "        Y_test = Y[X1_test_index,:][:,X2_test_index]\n",
    "\n",
    "        auc_dic[fold_count] = [] \n",
    "        aupr_dic[fold_count] = [] \n",
    "        \n",
    "        predtest2 = 0\n",
    "        \n",
    "        # model\n",
    "        for z in range(nof_trees):\n",
    "\n",
    "            chleft,chright,features2,thlist,featurelist,impuritylist,nodelist1 = ebuild_bd(X1_train,X2_train,Y_train,msleaf,cs) # building a randomized bi-clustering tree\n",
    "            leafnode,leafnode2,prednode,pred,indprednode,pred_rows,pred_cols = ebdtrain(X1_train,X2_train,chleft,chright,features2,thlist,Y_train)\n",
    "            leafnodetest,predtest,Ytest_vector = ebdtest(X1_test,X2_test,chleft,chright,features2,thlist,indprednode,prednode,Y_test,pred_rows,pred_cols) # Ytest is NOT used in the predictions!\n",
    "            predtest2 = predtest2 + predtest # add the prediction of new tree to the previous \n",
    "            predtest = predtest2 / float(z+1)\n",
    "\n",
    "            lr_fpr, lr_tpr, lr_thresholds = metrics.roc_curve(Ytest_vector, predtest)  # 计算ROC的值,lr_thresholds为阈值\n",
    "            lr_auc = metrics.auc(lr_fpr, lr_tpr)\n",
    "            print('auc:', lr_auc)\n",
    "            auc_dic[fold_count].append(lr_auc)\n",
    "\n",
    "\n",
    "            aupr = average_precision_score(Ytest_vector, predtest)\n",
    "            print('aupr:', aupr)\n",
    "            aupr_dic[fold_count].append(aupr)\n",
    "\n",
    "        fold_count += 1\n",
    "        print(\"===========================================\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(dataname):\n",
    "    if dataname in ['ERN', 'SRN']:\n",
    "        X1 = np.loadtxt('./dataset/'+str(dataname)+'/X1.txt',delimiter=\",\")\n",
    "        Y = np.loadtxt('./dataset/'+str(dataname)+'/Y.txt',delimiter=\",\")\n",
    "        X2 = np.loadtxt('./dataset/'+str(dataname)+'/X2.txt',delimiter=\",\")\n",
    "    else:\n",
    "        X1 = np.loadtxt('./dataset/'+str(dataname)+'/'+str(dataname)+'_X1.txt')\n",
    "        Y = np.loadtxt('./dataset/'+str(dataname)+'/'+str(dataname)+'_Y.txt')\n",
    "        X2 = np.loadtxt('./dataset/'+str(dataname)+'/'+str(dataname)+'_X2.txt')\n",
    "    return X1, X2, Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " ...\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]\n",
      " [0. 0. 0. ... 0. 0. 0.]]\n"
     ]
    }
   ],
   "source": [
    "X1, X2, Y = load_data(dataname)\n",
    "print(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled = [True, False]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "setting = 'B'\n",
    "if setting == 'C':\n",
    "    X1, Y = X2, np.transpose(Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================= Fold 0 =========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 210)\n",
      "72 out of the 210 total labels has more than one classes present\n",
      "========================================================================\n",
      "\n",
      "======================= Fold 1 =========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 210)\n",
      "82 out of the 210 total labels has more than one classes present\n",
      "========================================================================\n",
      "\n",
      "======================= Fold 2 =========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 210)\n",
      "96 out of the 210 total labels has more than one classes present\n",
      "========================================================================\n",
      "\n",
      "======================= Fold 3 =========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 210)\n",
      "42 out of the 210 total labels has more than one classes present\n",
      "========================================================================\n",
      "\n",
      "======================= Fold 4 =========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 210)\n",
      "76 out of the 210 total labels has more than one classes present\n",
      "========================================================================\n",
      "\n",
      "======================= Fold 5 =========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 210)\n",
      "88 out of the 210 total labels has more than one classes present\n",
      "========================================================================\n",
      "\n",
      "======================= Fold 6 =========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 210)\n",
      "99 out of the 210 total labels has more than one classes present\n",
      "========================================================================\n",
      "\n",
      "======================= Fold 7 =========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 210)\n",
      "89 out of the 210 total labels has more than one classes present\n",
      "========================================================================\n",
      "\n",
      "======================= Fold 8 =========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 210)\n",
      "72 out of the 210 total labels has more than one classes present\n",
      "========================================================================\n",
      "\n",
      "======================= Fold 9 =========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n",
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/model_selection/_split.py:293: FutureWarning: Setting a random_state has no effect since shuffle is False. This will raise an error in 0.24. You should leave random_state to its default (None), or set shuffle=True.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 210)\n",
      "53 out of the 210 total labels has more than one classes present\n",
      "========================================================================\n",
      "\n",
      "settingB dpii mlp shuffle = True\n",
      "auroc_micro: 0.9327 (0.0332)\n",
      "\n",
      "auroc_macro: 0.9151 (0.0433)\n",
      "\n",
      "aupr_micro: 0.8303 (0.0494)\n",
      "\n",
      "aupr_macro: 0.8308 (0.0614)\n",
      "\n",
      "======================= Fold 0 =========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 210)\n",
      "52 out of the 210 total labels has more than one classes present\n",
      "========================================================================\n",
      "\n",
      "======================= Fold 1 =========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 210)\n",
      "39 out of the 210 total labels has more than one classes present\n",
      "========================================================================\n",
      "\n",
      "======================= Fold 2 =========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 210)\n",
      "36 out of the 210 total labels has more than one classes present\n",
      "========================================================================\n",
      "\n",
      "======================= Fold 3 =========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21, 210)\n",
      "45 out of the 210 total labels has more than one classes present\n",
      "========================================================================\n",
      "\n",
      "======================= Fold 4 =========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 210)\n",
      "32 out of the 210 total labels has more than one classes present\n",
      "========================================================================\n",
      "\n",
      "======================= Fold 5 =========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 210)\n",
      "42 out of the 210 total labels has more than one classes present\n",
      "========================================================================\n",
      "\n",
      "======================= Fold 6 =========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 210)\n",
      "50 out of the 210 total labels has more than one classes present\n",
      "========================================================================\n",
      "\n",
      "======================= Fold 7 =========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 210)\n",
      "64 out of the 210 total labels has more than one classes present\n",
      "========================================================================\n",
      "\n",
      "======================= Fold 8 =========================================\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20, 210)\n",
      "35 out of the 210 total labels has more than one classes present\n",
      "========================================================================\n",
      "\n",
      "======================= Fold 9 =========================================\n",
      "(20, 210)\n",
      "65 out of the 210 total labels has more than one classes present\n",
      "========================================================================\n",
      "\n",
      "settingB dpii mlp shuffle = False\n",
      "auroc_micro: 0.7850 (0.1375)\n",
      "\n",
      "auroc_macro: 0.6989 (0.1682)\n",
      "\n",
      "aupr_micro: 0.5828 (0.1806)\n",
      "\n",
      "aupr_macro: 0.5870 (0.1837)\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.8/site-packages/sklearn/neural_network/_multilayer_perceptron.py:582: ConvergenceWarning: Stochastic Optimizer: Maximum iterations (300) reached and the optimization hasn't converged yet.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "for item in shuffled:\n",
    "    \n",
    "    metrics_to_calculate = ['auroc', 'aupr']\n",
    "    metric_values_per_fold = {}\n",
    "    if 'auroc' in metrics_to_calculate:\n",
    "        metric_values_per_fold['auroc_micro'] = []\n",
    "        metric_values_per_fold['auroc_macro'] = []\n",
    "    if 'aupr' in metrics_to_calculate:\n",
    "        metric_values_per_fold['aupr_micro'] = []\n",
    "        metric_values_per_fold['aupr_macro'] = []\n",
    "\n",
    "    kf = KFold(n_splits=10, shuffle=item,random_state=42)\n",
    "    fold_counter = 0\n",
    "\n",
    "    for train_index, test_index in kf.split(X1):\n",
    "        print('======================= Fold '+str(fold_counter)+' =========================================')\n",
    "\n",
    "        # split the dataset\n",
    "        X_train, X_test = X1[train_index], X1[test_index]\n",
    "        y_train, y_test = Y[train_index], Y[test_index]\n",
    "        \n",
    "        # scaler\n",
    "        scaler = None\n",
    "        if scale_type == 'standard':\n",
    "            scaler = StandardScaler()\n",
    "        elif scale_type == 'minmax':\n",
    "            scaler = MinMaxScaler()\n",
    "        if scaler is not None:\n",
    "            scaler.fit(X_train)\n",
    "            X_train = scaler.transform(X_train)\n",
    "            X_test = scaler.transform(X_test)\n",
    "\n",
    "        clf = None\n",
    "        # define the oneVSrest classifier with the base classifier\n",
    "        if method_name == 'random_forest':\n",
    "            clf = OneVsRestClassifier(RandomForestClassifier())\n",
    "        elif method_name == 'logistic_regression':\n",
    "            clf = OneVsRestClassifier(LogisticRegression(random_state=0))\n",
    "        elif method_name == 'mlp_per_target':\n",
    "            clf = OneVsRestClassifier(MLPClassifier(random_state=1, hidden_layer_sizes=(256), solver='adam', learning_rate='adaptive', max_iter=300)) # binary relevance approach that uses a neural network as the base classifier (so it creates as many neural networks as there are labels)\n",
    "        elif method_name == 'mlp':\n",
    "            clf = MLPClassifier(random_state=1, hidden_layer_sizes=(512), solver='adam', learning_rate='adaptive', max_iter=300) # standard neural network\n",
    "        else:\n",
    "            raise ValueError(\"invalid method name given\")\n",
    "            \n",
    "        # fit the classifier on the training set\n",
    "        clf.fit(X_train, y_train)\n",
    "\n",
    "        # generate probability predictions for every sample in the test set\n",
    "        y_pred = clf.predict_proba(X_test)\n",
    "\n",
    "        print(str(y_pred.shape))\n",
    "\n",
    "        # calculate the performance metrics on the test set\n",
    "        if 'auroc' in metrics_to_calculate:\n",
    "            metric_values_per_fold['auroc_micro'].append(roc_auc_score(y_test, y_pred, average='micro'))\n",
    "\n",
    "            # This is not really important as we are only interested in the micro measures.\n",
    "            # Nevertheless, I basically do the macro averaging by hand so that I can skip labels that have only samples with one class\n",
    "            roc_auc_per_label = []\n",
    "            for label_idx in range(Y.shape[1]): # 0是行 1是列\n",
    "                if len(set(y_test[:, label_idx])) >= 2: # here test is validation\n",
    "                    roc_auc_per_label.append(roc_auc_score(y_test[:, label_idx], y_pred[:, label_idx]))\n",
    "            print(str(len(roc_auc_per_label))+' out of the '+str(y_test.shape[1])+' total labels has more than one classes present')\n",
    "\n",
    "            metric_values_per_fold['auroc_macro'].append(np.mean(roc_auc_per_label))\n",
    "\n",
    "\n",
    "        if 'aupr' in metrics_to_calculate:\n",
    "            metric_values_per_fold['aupr_micro'].append(average_precision_score(y_test, y_pred, average='micro'))\n",
    "\n",
    "            aupr_per_label = []\n",
    "            for label_idx in range(Y.shape[1]):\n",
    "                if len(set(y_test[:, label_idx])) >= 2:\n",
    "                    aupr_per_label.append(average_precision_score(y_test[:, label_idx], y_pred[:, label_idx]))\n",
    "\n",
    "            metric_values_per_fold['aupr_macro'].append(np.mean(aupr_per_label))\n",
    "\n",
    "\n",
    "        fold_counter += 1\n",
    "        print('========================================================================')\n",
    "        print('')\n",
    "        \n",
    "    # calculate the mean and std for every metric measured during training and validation\n",
    "    print('setting' + str(setting), str(dataname), str(method_name), 'shuffle = ' + str(item))\n",
    "    for metric_name in metric_values_per_fold.keys():\n",
    "        print(metric_name+': '+ str('%.4f' % np.mean(metric_values_per_fold[metric_name])) +' ('+ str('%.4f' % np.std(metric_values_per_fold[metric_name])) +')')\n",
    "        print('')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
